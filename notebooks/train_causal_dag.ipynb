{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77116c06",
   "metadata": {},
   "source": [
    "# Train Causal DAG — ARGUS Phase 2\n",
    "\n",
    "This notebook discovers and trains the causal DAG for the Beas–Brahmaputra\n",
    "river basins using the PC algorithm (constraint-based causal discovery)\n",
    "and validates the graph with interventional queries.\n",
    "\n",
    "**Owner:** Rogesh · **Service:** `causal_engine`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a03d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Synthetic hydro-met data for DAG discovery\n",
    "np.random.seed(42)\n",
    "N = 2000  # samples\n",
    "\n",
    "# Ground truth causal model:\n",
    "# rainfall_upper → upstream_level → midstream_level → downstream_level → flood_risk\n",
    "# rainfall_upper → soil_moisture → flood_risk\n",
    "# dam_release → midstream_level\n",
    "\n",
    "rainfall_upper = np.random.exponential(10, N)\n",
    "rainfall_lower = 0.6 * rainfall_upper + np.random.normal(0, 3, N)\n",
    "snowmelt = np.random.uniform(0, 5, N)\n",
    "soil_moisture = 0.3 + 0.4 * (rainfall_upper / rainfall_upper.max()) + np.random.normal(0, 0.1, N)\n",
    "soil_moisture = np.clip(soil_moisture, 0, 1)\n",
    "dam_release = np.random.uniform(10, 100, N)\n",
    "tributary_flow = np.random.uniform(5, 50, N)\n",
    "\n",
    "upstream_level = 1.5 + 0.08 * rainfall_upper + 0.03 * snowmelt + np.random.normal(0, 0.3, N)\n",
    "midstream_level = 0.5 * upstream_level + 0.02 * dam_release + 0.01 * tributary_flow + 0.3 * soil_moisture + np.random.normal(0, 0.2, N)\n",
    "downstream_level = 0.7 * midstream_level + 0.02 * rainfall_lower + np.random.normal(0, 0.2, N)\n",
    "\n",
    "# Flood risk: sigmoid of downstream level\n",
    "flood_risk = 1 / (1 + np.exp(-(downstream_level - 3.5) * 2))\n",
    "flood_risk += 0.1 * soil_moisture\n",
    "flood_risk = np.clip(flood_risk, 0, 1)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'rainfall_upper': rainfall_upper,\n",
    "    'rainfall_lower': rainfall_lower,\n",
    "    'snowmelt': snowmelt,\n",
    "    'soil_moisture': soil_moisture,\n",
    "    'dam_release': dam_release,\n",
    "    'tributary_flow': tributary_flow,\n",
    "    'upstream_level': upstream_level,\n",
    "    'midstream_level': midstream_level,\n",
    "    'downstream_level': downstream_level,\n",
    "    'flood_risk': flood_risk,\n",
    "})\n",
    "\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "df.describe().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ed9ad2",
   "metadata": {},
   "source": [
    "## Correlation-based DAG Discovery (PC Algorithm Approximation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6404d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute partial correlations as proxy for conditional independence\n",
    "corr = df.corr()\n",
    "\n",
    "# Threshold for edge existence\n",
    "EDGE_THRESHOLD = 0.15\n",
    "\n",
    "variables = list(df.columns)\n",
    "edges = []\n",
    "\n",
    "# Known causal ordering (domain knowledge)\n",
    "causal_order = [\n",
    "    'rainfall_upper', 'rainfall_lower', 'snowmelt',\n",
    "    'soil_moisture', 'dam_release', 'tributary_flow',\n",
    "    'upstream_level', 'midstream_level', 'downstream_level',\n",
    "    'flood_risk',\n",
    "]\n",
    "\n",
    "# Discover edges: only from earlier to later in causal order\n",
    "for i, src in enumerate(causal_order):\n",
    "    for j, tgt in enumerate(causal_order):\n",
    "        if j <= i:\n",
    "            continue\n",
    "        r = abs(corr.loc[src, tgt])\n",
    "        if r > EDGE_THRESHOLD:\n",
    "            edges.append({\n",
    "                'source': src,\n",
    "                'target': tgt,\n",
    "                'weight': round(float(r), 3),\n",
    "                'lag_hours': round((j - i) * 2.0, 1),  # heuristic lag\n",
    "                'mechanism': 'hydrological' if 'level' in tgt or 'level' in src else 'meteorological',\n",
    "            })\n",
    "\n",
    "print(f'Discovered {len(edges)} causal edges')\n",
    "for e in edges:\n",
    "    print(f\"  {e['source']:20s} → {e['target']:20s}  w={e['weight']:.3f}  lag={e['lag_hours']}h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467ca536",
   "metadata": {},
   "source": [
    "## Build & Save Causal DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c068e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build node list\n",
    "nodes = []\n",
    "child_map = {}\n",
    "parent_map = {}\n",
    "for e in edges:\n",
    "    child_map.setdefault(e['source'], []).append(e['target'])\n",
    "    parent_map.setdefault(e['target'], []).append(e['source'])\n",
    "\n",
    "for var in variables:\n",
    "    nodes.append({\n",
    "        'node_id': var,\n",
    "        'variable': var,\n",
    "        'parents': parent_map.get(var, []),\n",
    "        'children': child_map.get(var, []),\n",
    "    })\n",
    "\n",
    "dag = {\n",
    "    'dag_id': 'beas_brahmaputra_v1',\n",
    "    'nodes': nodes,\n",
    "    'edges': edges,\n",
    "    'version': '1.0.0',\n",
    "    'created_at': datetime.now().isoformat(),\n",
    "}\n",
    "\n",
    "# Save\n",
    "out_path = Path('../shared/causal_dag/beas_brahmaputra_v1.json')\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "out_path.write_text(json.dumps(dag, indent=2))\n",
    "print(f'DAG saved to {out_path}')\n",
    "print(f'  Nodes: {len(nodes)}, Edges: {len(edges)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4170a2ac",
   "metadata": {},
   "source": [
    "## Validate: Interventional Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0170d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from services.causal_engine.dag import load_dag\n",
    "from services.causal_engine.gnn import CausalGNNEngine\n",
    "from services.causal_engine.interventions import InterventionAPI\n",
    "from shared.models.phase2 import InterventionRequest\n",
    "\n",
    "dag_model = load_dag(str(out_path))\n",
    "engine = CausalGNNEngine(dag_model)\n",
    "api = InterventionAPI(engine)\n",
    "\n",
    "# Test: do(rainfall_upper = 0) → should reduce flood_risk\n",
    "result = api.run(InterventionRequest(\n",
    "    variable='rainfall_upper',\n",
    "    value=0.0,\n",
    "    target_variables=['flood_risk', 'downstream_level'],\n",
    "    context={'soil_moisture': 0.5, 'dam_release': 0.3},\n",
    "))\n",
    "\n",
    "print('Intervention: do(rainfall_upper = 0)')\n",
    "print(f'  Original:       {result.original_values}')\n",
    "print(f'  Counterfactual: {result.counterfactual_values}')\n",
    "print(f'  Causal Effects: {result.causal_effects}')\n",
    "print(f'  Confidence:     {result.confidence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807036b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity analysis: sweep rainfall_upper 0 → 1\n",
    "sweep = api.sensitivity_analysis(\n",
    "    variable='rainfall_upper',\n",
    "    values=np.linspace(0, 1, 11).tolist(),\n",
    "    target='flood_risk',\n",
    "    context={'soil_moisture': 0.5, 'dam_release': 0.3},\n",
    ")\n",
    "\n",
    "print('Sensitivity: rainfall_upper → flood_risk')\n",
    "for s in sweep:\n",
    "    print(f\"  rain={s['do_value']:.1f} → risk_cf={s['counterfactual']:.4f}  (Δ={s['effect']:+.4f})\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
