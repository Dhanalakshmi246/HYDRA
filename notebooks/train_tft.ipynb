{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6691cf4c",
   "metadata": {},
   "source": [
    "# Train TFT (Temporal Fusion Transformer) — ARGUS Phase 2\n",
    "\n",
    "Trains a simplified Temporal Fusion Transformer for multi-horizon\n",
    "flood risk forecasting (24h ahead with quantile uncertainty).\n",
    "\n",
    "**Owner:** Sabarish · **Service:** `prediction` (deep track)\n",
    "\n",
    "Since full TFT requires PyTorch Forecasting, this notebook uses a\n",
    "simplified attention-based LSTM architecture as a portable fallback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f145f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic temporal flood-risk data\n",
    "N_DAYS = 365\n",
    "HOURS_PER_DAY = 24\n",
    "N = N_DAYS * HOURS_PER_DAY\n",
    "\n",
    "t = np.arange(N)\n",
    "# Monsoon seasonality (June-Sept peak)\n",
    "monsoon = 0.5 + 0.4 * np.sin(2 * np.pi * (t / (365 * 24) - 0.4))\n",
    "monsoon = np.clip(monsoon, 0, 1)\n",
    "\n",
    "rainfall = monsoon * np.random.exponential(10, N) + np.random.normal(0, 2, N)\n",
    "rainfall = np.clip(rainfall, 0, None)\n",
    "\n",
    "water_level = np.zeros(N)\n",
    "water_level[0] = 2.0\n",
    "for i in range(1, N):\n",
    "    water_level[i] = 0.95 * water_level[i-1] + 0.005 * rainfall[i] + 0.001 * monsoon[i] + np.random.normal(0, 0.05)\n",
    "    water_level[i] = max(0.5, water_level[i])\n",
    "\n",
    "soil_moisture = 0.3 + 0.4 * monsoon + 0.1 * np.random.randn(N)\n",
    "soil_moisture = np.clip(soil_moisture, 0, 1)\n",
    "\n",
    "risk = 1 / (1 + np.exp(-(water_level - 3.0) * 2)) + 0.1 * soil_moisture\n",
    "risk = np.clip(risk, 0, 1)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'hour': t,\n",
    "    'rainfall_mm': rainfall,\n",
    "    'water_level_m': water_level,\n",
    "    'soil_moisture': soil_moisture,\n",
    "    'monsoon_signal': monsoon,\n",
    "    'risk': risk,\n",
    "})\n",
    "\n",
    "print(f'Dataset: {df.shape}')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee7ba2e",
   "metadata": {},
   "source": [
    "## Prepare Sequences for LSTM Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f2d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOKBACK = 48     # 48 hours of history\n",
    "HORIZON = 24      # 24 hours ahead\n",
    "FEATURES = ['rainfall_mm', 'water_level_m', 'soil_moisture', 'monsoon_signal']\n",
    "TARGET = 'risk'\n",
    "\n",
    "# Normalise features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df[FEATURES] = scaler.fit_transform(df[FEATURES])\n",
    "\n",
    "# Create sequences\n",
    "X, Y = [], []\n",
    "values = df[FEATURES].values\n",
    "targets = df[TARGET].values\n",
    "\n",
    "for i in range(LOOKBACK, len(df) - HORIZON):\n",
    "    X.append(values[i - LOOKBACK:i])\n",
    "    Y.append(targets[i:i + HORIZON])\n",
    "\n",
    "X = np.array(X, dtype=np.float32)\n",
    "Y = np.array(Y, dtype=np.float32)\n",
    "\n",
    "# Train/val split\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_val = X[:split], X[split:]\n",
    "Y_train, Y_val = Y[:split], Y[split:]\n",
    "\n",
    "print(f'X_train: {X_train.shape}, Y_train: {Y_train.shape}')\n",
    "print(f'X_val:   {X_val.shape},   Y_val:   {Y_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18fc590",
   "metadata": {},
   "source": [
    "## Define Attention LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    TORCH_OK = True\n",
    "except ImportError:\n",
    "    TORCH_OK = False\n",
    "    print('PyTorch not available — skipping model training')\n",
    "\n",
    "if TORCH_OK:\n",
    "    class AttentionLSTM(nn.Module):\n",
    "        \"\"\"LSTM with temporal attention for multi-horizon forecasting.\"\"\"\n",
    "        def __init__(self, n_features=4, hidden=64, n_layers=2, horizon=24):\n",
    "            super().__init__()\n",
    "            self.lstm = nn.LSTM(n_features, hidden, n_layers, batch_first=True, dropout=0.1)\n",
    "            self.attention = nn.Linear(hidden, 1)\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(hidden, 32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32, horizon),\n",
    "                nn.Sigmoid(),\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            lstm_out, _ = self.lstm(x)  # (B, T, H)\n",
    "            # Attention weights\n",
    "            attn_w = torch.softmax(self.attention(lstm_out), dim=1)  # (B, T, 1)\n",
    "            context = (attn_w * lstm_out).sum(dim=1)  # (B, H)\n",
    "            return self.fc(context)  # (B, horizon)\n",
    "    \n",
    "    model = AttentionLSTM(n_features=len(FEATURES), horizon=HORIZON)\n",
    "    print(f'Model parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae41b2c",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55960df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_OK:\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "    \n",
    "    train_ds = TensorDataset(torch.tensor(X_train), torch.tensor(Y_train))\n",
    "    val_ds = TensorDataset(torch.tensor(X_val), torch.tensor(Y_val))\n",
    "    train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size=128)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    EPOCHS = 20\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for xb, yb in train_dl:\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * len(xb)\n",
    "        train_loss /= len(train_ds)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_dl:\n",
    "                pred = model(xb)\n",
    "                val_loss += criterion(pred, yb).item() * len(xb)\n",
    "        val_loss /= len(val_ds)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            print(f'Epoch {epoch+1:3d}/{EPOCHS}  train_loss={train_loss:.5f}  val_loss={val_loss:.5f}')\n",
    "    \n",
    "    # Save model\n",
    "    model_path = Path('../models/tft_attention_lstm.pt')\n",
    "    model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f'\\nModel saved to {model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10082405",
   "metadata": {},
   "source": [
    "## Evaluate & Visualise Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a19cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_OK:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        sample_x = torch.tensor(X_val[:5])\n",
    "        preds = model(sample_x).numpy()\n",
    "        actuals = Y_val[:5]\n",
    "    \n",
    "    for i in range(3):\n",
    "        print(f'\\nSample {i+1}:')\n",
    "        print(f'  Predicted (first 6h): {preds[i, :6].round(3)}')\n",
    "        print(f'  Actual    (first 6h): {actuals[i, :6].round(3)}')\n",
    "        mae = np.mean(np.abs(preds[i] - actuals[i]))\n",
    "        print(f'  MAE: {mae:.4f}')\n",
    "    \n",
    "    overall_mae = np.mean(np.abs(preds - actuals))\n",
    "    print(f'\\nOverall MAE (5 samples): {overall_mae:.4f}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
