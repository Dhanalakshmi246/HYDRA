"""CHORUS Global Language Support â€” Phase 6 multi-language expansion.

Adds Vietnamese, Khmer, Portuguese (Mozambique), and Nepali to the
CHORUS voice-driven community sensing pipeline.

Architecture:
  Whisper ASR (auto-detects language) â†’ Language-specific BERT classifier
  â†’ Keyword fallback for unsupported languages
  â†’ Language-specific TTS for alert responses
"""

from __future__ import annotations

from dataclasses import dataclass
from enum import Enum
from typing import Optional

import structlog

logger = structlog.get_logger(__name__)


# â”€â”€ Classification Result â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class FloodLabel(str, Enum):
    """CHORUS flood classification labels."""
    FLOOD_PRECURSOR = "FLOOD_PRECURSOR"
    FLOOD_ACTIVE = "FLOOD_ACTIVE"
    FLOOD_AFTERMATH = "FLOOD_AFTERMATH"
    INFRASTRUCTURE_DAMAGE = "INFRASTRUCTURE_DAMAGE"
    EVACUATION_REQUEST = "EVACUATION_REQUEST"
    RESOURCE_REQUEST = "RESOURCE_REQUEST"
    UNRELATED = "UNRELATED"


@dataclass
class ClassificationResult:
    """Result from CHORUS text classification."""
    label: FloodLabel
    confidence: float
    method: str                  # "bert", "zero_shot_keyword", "multilingual"
    language: str = "unknown"
    raw_text: Optional[str] = None
    translated_text: Optional[str] = None


# â”€â”€ Language Configs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

GLOBAL_LANGUAGE_CONFIG = {
    # â”€â”€ South Asia (Phase 5 â€” already working) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    "hi": {
        "name": "Hindi",
        "asr": "whisper",
        "tts": "indic_tts",
        "classifier_model": "ai4bharat/indic-bert",
        "flood_keywords": ["à¤¬à¤¾à¤¢à¤¼", "à¤ªà¤¾à¤¨à¥€", "à¤¨à¤¦à¥€", "à¤¬à¤¾à¤°à¤¿à¤¶", "à¤¤à¤¬à¤¾à¤¹à¥€", "à¤œà¤²à¤¸à¥à¤¤à¤°"],
        "alert_templates": {
            "WARNING": "âš ï¸ à¤¬à¤¾à¤¢à¤¼ à¤šà¥‡à¤¤à¤¾à¤µà¤¨à¥€: {village} à¤®à¥‡à¤‚ {hours} à¤˜à¤‚à¤Ÿà¥‡ à¤®à¥‡à¤‚ à¤¬à¤¾à¤¢à¤¼ à¤•à¤¾ à¤–à¤¤à¤°à¤¾à¥¤ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤¤à¥ˆà¤¯à¤¾à¤° à¤°à¤¹à¥‡à¤‚à¥¤",
            "EMERGENCY": "ðŸš¨ à¤†à¤ªà¤¾à¤¤à¤•à¤¾à¤²à¥€à¤¨: {village} à¤®à¥‡à¤‚ à¤¤à¥à¤°à¤‚à¤¤ à¤¨à¤¿à¤•à¤¾à¤¸à¥€à¥¤ à¤Šà¤à¤šà¥€ à¤œà¤—à¤¹ à¤ªà¤° à¤œà¤¾à¤à¤à¥¤",
        },
        "active": True,
    },
    "bn": {
        "name": "Bengali",
        "asr": "whisper",
        "tts": "indic_tts",
        "classifier_model": "ai4bharat/indic-bert",
        "flood_keywords": ["à¦¬à¦¨à§à¦¯à¦¾", "à¦œà¦²", "à¦¨à¦¦à§€", "à¦¬à§ƒà¦·à§à¦Ÿà¦¿", "à¦œà¦²à¦¸à§à¦¤à¦°", "à¦¡à§à¦¬à§‡ à¦¯à¦¾à¦“à¦¯à¦¼à¦¾"],
        "alert_templates": {
            "WARNING": "âš ï¸ à¦¬à¦¨à§à¦¯à¦¾ à¦¸à¦¤à¦°à§à¦•à¦¤à¦¾: {village}-à¦ {hours} à¦˜à¦¨à§à¦Ÿà¦¾à¦° à¦®à¦§à§à¦¯à§‡ à¦¬à¦¨à§à¦¯à¦¾à¦° à¦à§à¦à¦•à¦¿à¥¤ à¦ªà§à¦°à¦¸à§à¦¤à§à¦¤ à¦¥à¦¾à¦•à§à¦¨à¥¤",
            "EMERGENCY": "ðŸš¨ à¦œà¦°à§à¦°à¦¿: {village}-à¦ à¦à¦–à¦¨à¦‡ à¦¸à¦°à§‡ à¦¯à¦¾à¦¨à¥¤ à¦‰à¦à¦šà§ à¦œà¦¾à¦¯à¦¼à¦—à¦¾à¦¯à¦¼ à¦¯à¦¾à¦¨à¥¤",
        },
        "active": True,
    },
    "as": {
        "name": "Assamese",
        "asr": "whisper",
        "tts": "indic_tts",
        "classifier_model": "ai4bharat/indic-bert",
        "flood_keywords": ["à¦¬à¦¾à¦¨", "à¦ªà¦¾à¦¨à§€", "à¦¨à§ˆ", "à¦¬à§°à¦·à§à¦£", "à¦œà¦²à¦ªà§ƒà¦·à§à¦ "],
        "alert_templates": {
            "WARNING": "âš ï¸ à¦¬à¦¾à¦¨ à¦¸à¦¤à§°à§à¦•à¦¤à¦¾: {village}à¦¤ {hours} à¦˜à¦£à§à¦Ÿà¦¾à§° à¦­à¦¿à¦¤à§°à¦¤ à¦¬à¦¾à¦¨à§° à¦†à¦¶à¦‚à¦•à¦¾à¥¤",
            "EMERGENCY": "ðŸš¨ à¦œà§°à§à§°à§€: {village}à§° à¦ªà§°à¦¾ à¦à¦¤à¦¿à¦¯à¦¼à¦¾à¦‡ à¦†à¦à¦¤à§°à¦¿ à¦¯à¦¾à¦“à¦•à¥¤",
        },
        "active": True,
    },

    # â”€â”€ Phase 6 New Languages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    "vi": {
        "name": "Vietnamese",
        "asr": "whisper",
        "tts": "openai_tts",
        "classifier_model": "joeddav/xlm-roberta-large-xnli",
        "flood_keywords": [
            "lÅ© lá»¥t", "ngáº­p", "nÆ°á»›c dÃ¢ng", "vá»¡ Ä‘Ãª", "mÆ°a lá»›n",
            "sáº¡t lá»Ÿ", "triá»u cÆ°á»ng", "xáº£ lÅ©", "sÃ´ng dÃ¢ng", "ngáº­p Ãºng",
        ],
        "alert_templates": {
            "WARNING": "âš ï¸ Cáº£nh bÃ¡o lÅ© lá»¥t: {village} cÃ³ nguy cÆ¡ ngáº­p trong {hours} giá» tá»›i. HÃ£y chuáº©n bá»‹ sÆ¡ tÃ¡n.",
            "EMERGENCY": "ðŸš¨ KHáº¨N Cáº¤P: SÆ¡ tÃ¡n {village} ngay láº­p tá»©c. Di chuyá»ƒn Ä‘áº¿n vÃ¹ng cao.",
        },
        "active": True,
    },
    "km": {
        "name": "Khmer",
        "asr": "whisper",
        "tts": "openai_tts",
        "classifier_model": "google/muril-base-cased",
        "flood_keywords": [
            "áž‘áž¹áž€áž‡áŸ†áž“áž“áŸ‹", "áž‘áž¹áž€áž¡áž¾áž„", "ážáŸ’áž–ážŸáŸ‹", "áž—áŸ’áž›áŸ€áž„", "áž‘áŸ†áž“áž”áŸ‹",
            "áž‡áŸ†áž“áž“áŸ‹", "áž–áŸ’ážšáŸ‚áž€", "ážŸáŸ’áž‘áž¹áž„",
        ],
        "alert_templates": {
            "WARNING": "âš ï¸ áž€áž¶ážšáž–áŸ’ážšáž˜áž¶áž“áž‘áž¹áž€áž‡áŸ†áž“áž“áŸ‹: {village} áž˜áž¶áž“áž‚áŸ’ážšáŸ„áŸ‡ážáŸ’áž“áž¶áž€áŸ‹áž€áŸ’áž“áž»áž„ážšáž™áŸˆáž–áŸáž› {hours} áž˜áŸ‰áŸ„áž„áŸ”",
            "EMERGENCY": "ðŸš¨ áž”áž“áŸ’áž‘áž¶áž“áŸ‹: áž‡áž˜áŸ’áž›áŸ€ážŸ {village} áž—áŸ’áž›áž¶áž˜áŸ—áŸ” áž‘áŸ…áž€áž“áŸ’áž›áŸ‚áž„ážáŸ’áž–ážŸáŸ‹áŸ”",
        },
        "active": True,
    },
    "pt": {
        "name": "Portuguese",
        "asr": "whisper",
        "tts": "openai_tts",
        "classifier_model": "neuralmind/bert-base-portuguese-cased",
        "flood_keywords": [
            "cheia", "inundaÃ§Ã£o", "Ã¡gua subindo", "rio transbordou",
            "chuva forte", "deslizamento", "alagamento", "enchente",
        ],
        "alert_templates": {
            "WARNING": "âš ï¸ Alerta de cheia: {village} em risco de inundaÃ§Ã£o nas prÃ³ximas {hours} horas. Prepare-se para evacuar.",
            "EMERGENCY": "ðŸš¨ EMERGÃŠNCIA: Evacue {village} imediatamente. VÃ¡ para terreno elevado.",
        },
        "active": True,
    },
    "ne": {
        "name": "Nepali",
        "asr": "whisper",
        "tts": "indic_tts",
        "classifier_model": "ai4bharat/indic-bert",
        "flood_keywords": [
            "à¤¬à¤¾à¤¢à¥€", "à¤ªà¤¾à¤¨à¥€ à¤¬à¤¢à¥à¤¯à¥‹", "à¤¨à¤¦à¥€ à¤‰à¤°à¥à¤²à¤¿à¤¯à¥‹", "à¤µà¤°à¥à¤·à¤¾", "à¤ªà¤¹à¤¿à¤°à¥‹",
            "à¤¡à¥à¤¬à¤¾à¤¨", "à¤œà¤²à¤¸à¥à¤¤à¤°", "à¤­à¥‡à¤²",
        ],
        "alert_templates": {
            "WARNING": "âš ï¸ à¤¬à¤¾à¤¢à¥€ à¤šà¥‡à¤¤à¤¾à¤µà¤¨à¥€: {village} à¤®à¤¾ {hours} à¤˜à¤£à¥à¤Ÿà¤¾ à¤­à¤¿à¤¤à¥à¤° à¤¬à¤¾à¤¢à¥€à¤•à¥‹ à¤œà¥‹à¤–à¤¿à¤® à¤›à¥¤ à¤¤à¤¯à¤¾à¤° à¤°à¤¹à¤¨à¥à¤¹à¥‹à¤¸à¥à¥¤",
            "EMERGENCY": "ðŸš¨ à¤†à¤ªà¤¤à¤•à¤¾à¤²à¥€à¤¨: {village} à¤¬à¤¾à¤Ÿ à¤¤à¥à¤°à¥à¤¨à¥à¤¤à¥ˆ à¤¸à¤°à¥à¤¨à¥à¤¹à¥‹à¤¸à¥à¥¤ à¤®à¤¾à¤¥à¤¿à¤²à¥à¤²à¥‹ à¤ à¤¾à¤‰à¤à¤®à¤¾ à¤œà¤¾à¤¨à¥à¤¹à¥‹à¤¸à¥à¥¤",
        },
        "active": True,
    },
    "my": {
        "name": "Burmese",
        "asr": "whisper",
        "tts": "openai_tts",
        "classifier_model": "google/muril-base-cased",
        "flood_keywords": [
            "á€›á€±á€€á€¼á€®á€¸", "á€›á€±á€œá€½á€¾á€™á€ºá€¸", "á€™á€­á€¯á€¸á€€á€¼á€®á€¸", "á€™á€¼á€…á€ºá€›á€±",
        ],
        "alert_templates": {
            "WARNING": "âš ï¸ á€›á€±á€€á€¼á€®á€¸á€žá€á€­á€•á€±á€¸á€á€»á€€á€º: {village} á€á€½á€„á€º {hours} á€”á€¬á€›á€®á€¡á€á€½á€„á€ºá€¸ á€›á€±á€€á€¼á€®á€¸á€”á€­á€¯á€„á€ºá€á€¼á€±á€›á€¾á€­á€žá€Šá€ºá‹",
            "EMERGENCY": "ðŸš¨ á€¡á€›á€±á€¸á€•á€±á€«á€º: {village} á€™á€¾ á€á€»á€€á€ºá€á€»á€„á€ºá€¸á€›á€½á€¾á€±á€·á€•á€¼á€±á€¬á€„á€ºá€¸á€•á€«á‹",
        },
        "active": False,   # Pending ASR quality validation
    },
}


# â”€â”€ Universal Flood Keywords (zero-shot fallback) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

UNIVERSAL_FLOOD_KEYWORDS = {
    # These work across languages via Whisper translation mode
    "flood", "water", "river", "rising", "overflow", "danger",
    "inundation", "submerged", "evacuation", "heavy rain",
    "dam", "embankment", "breach", "landslide", "rescue",
}


# â”€â”€ Classifier â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class GlobalCHORUSClassifier:
    """
    Multi-language CHORUS classifier using language detection + routing.

    Flow:
    1. Whisper ASR auto-detects language from audio
    2. Route to language-specific BERT model if available
    3. Fall back to zero-shot keyword matching for unsupported languages

    This means CHORUS can process reports in ANY language â€”
    just with higher accuracy for supported ones.
    """

    def __init__(self):
        self._loaded_models: dict[str, object] = {}
        logger.info(
            "chorus_classifier_init",
            supported_languages=len([
                c for c in GLOBAL_LANGUAGE_CONFIG.values() if c["active"]
            ]),
            total_languages=len(GLOBAL_LANGUAGE_CONFIG),
        )

    def classify(
        self,
        text: str,
        detected_language: str,
    ) -> ClassificationResult:
        """
        Classify a CHORUS report into flood-related categories.

        Args:
            text: Transcribed text from Whisper ASR
            detected_language: ISO 639-1 language code from Whisper

        Returns:
            ClassificationResult with label, confidence, method
        """
        config = GLOBAL_LANGUAGE_CONFIG.get(detected_language)

        if not config or not config["active"]:
            logger.info(
                "chorus_using_zero_shot",
                language=detected_language,
                reason="unsupported_or_inactive",
            )
            result = self._zero_shot_classify(text)
            result.language = detected_language
            return result

        # Use language-specific keyword + BERT classification
        result = self._keyword_classify(text, config)
        if result.confidence >= 0.6:
            result.language = detected_language
            return result

        # Attempt BERT classification for higher accuracy
        bert_result = self._bert_classify(text, config)
        if bert_result.confidence > result.confidence:
            bert_result.language = detected_language
            return bert_result

        result.language = detected_language
        return result

    def _keyword_classify(
        self,
        text: str,
        config: dict,
    ) -> ClassificationResult:
        """
        Keyword-based classification using language-specific flood terms.
        Fast, no model loading required â€” good for edge / offline.
        """
        text_lower = text.lower()
        keywords = config.get("flood_keywords", [])

        hit_count = sum(1 for kw in keywords if kw.lower() in text_lower)
        confidence = min(0.95, hit_count * 0.18)

        # Classify severity by keyword density
        if hit_count >= 4:
            label = FloodLabel.FLOOD_ACTIVE
        elif hit_count >= 2:
            label = FloodLabel.FLOOD_PRECURSOR
        elif hit_count >= 1:
            label = FloodLabel.FLOOD_PRECURSOR
        else:
            label = FloodLabel.UNRELATED

        # Check for evacuation-specific keywords
        evac_keywords = ["evacuation", "evacuate", "rescue", "help", "trapped",
                         "sÆ¡ tÃ¡n", "à¤¨à¤¿à¤•à¤¾à¤¸à¥€", "à¦‰à¦¦à§à¦§à¦¾à¦°", "à¦¬à¦¾à¦¨à¦¤", "cá»©u"]
        if any(kw in text_lower for kw in evac_keywords):
            label = FloodLabel.EVACUATION_REQUEST
            confidence = max(confidence, 0.75)

        return ClassificationResult(
            label=label,
            confidence=round(confidence, 3),
            method="keyword",
            raw_text=text,
        )

    def _bert_classify(
        self,
        text: str,
        config: dict,
    ) -> ClassificationResult:
        """
        Zero-shot NLI classification using xlm-roberta-large-xnli.

        Uses HuggingFace zero-shot-classification pipeline with
        multilingual NLI model â€” works across all CHORUS languages
        without per-language fine-tuning.
        """
        model_name = config.get(
            "classifier_model", "joeddav/xlm-roberta-large-xnli"
        )

        # Lazy-load and cache the pipeline
        if model_name not in self._loaded_models:
            try:
                from transformers import pipeline as hf_pipeline

                self._loaded_models[model_name] = hf_pipeline(
                    "zero-shot-classification",
                    model=model_name,
                    device=-1,  # CPU for edge / RPi deployment
                )
                logger.info("nli_model_loaded", model=model_name)
            except Exception as exc:
                logger.warning(
                    "nli_model_load_failed",
                    model=model_name,
                    error=str(exc),
                )
                # Fall back to keyword classification
                return self._keyword_classify(text, config)

        classifier = self._loaded_models[model_name]

        # Candidate labels match FloodLabel enum values
        candidate_labels = [
            "active flooding",
            "flood warning or precursor",
            "evacuation request",
            "infrastructure damage",
            "resource or rescue request",
            "unrelated to flooding",
        ]
        label_map = {
            "active flooding": FloodLabel.FLOOD_ACTIVE,
            "flood warning or precursor": FloodLabel.FLOOD_PRECURSOR,
            "evacuation request": FloodLabel.EVACUATION_REQUEST,
            "infrastructure damage": FloodLabel.INFRASTRUCTURE_DAMAGE,
            "resource or rescue request": FloodLabel.RESOURCE_REQUEST,
            "unrelated to flooding": FloodLabel.UNRELATED,
        }

        try:
            result = classifier(
                text,
                candidate_labels,
                hypothesis_template="This text is about {}.",
                multi_label=False,
            )
            top_label = result["labels"][0]
            top_score = result["scores"][0]

            flood_label = label_map.get(top_label, FloodLabel.UNRELATED)

            logger.info(
                "nli_classification",
                model=model_name,
                label=flood_label.value,
                confidence=round(top_score, 3),
                top_3=list(zip(result["labels"][:3], [
                    round(s, 3) for s in result["scores"][:3]
                ])),
            )

            return ClassificationResult(
                label=flood_label,
                confidence=round(top_score, 3),
                method="zero_shot_nli",
                raw_text=text,
            )
        except Exception as exc:
            logger.warning(
                "nli_inference_failed",
                error=str(exc),
            )
            return self._keyword_classify(text, config)

    def _zero_shot_classify(self, text: str) -> ClassificationResult:
        """
        Keyword-based zero-shot fallback for any language.

        Uses Whisper's translation mode to get English text,
        then matches against universal flood keyword list.
        Works for any of Whisper's 97 supported languages.
        """
        text_lower = text.lower()
        hit_count = sum(1 for kw in UNIVERSAL_FLOOD_KEYWORDS if kw in text_lower)
        confidence = min(0.9, hit_count * 0.15)

        label = (
            FloodLabel.FLOOD_PRECURSOR if confidence > 0.3
            else FloodLabel.UNRELATED
        )

        return ClassificationResult(
            label=label,
            confidence=round(confidence, 3),
            method="zero_shot_keyword",
            raw_text=text,
        )

    def get_alert_text(
        self,
        language: str,
        level: str,
        village: str,
        hours: int = 0,
    ) -> str:
        """
        Generate localised alert text for a given language.

        Args:
            language: ISO 639-1 code
            level: "WARNING" or "EMERGENCY"
            village: Village or ward name
            hours: Hours until expected flood
        """
        config = GLOBAL_LANGUAGE_CONFIG.get(language)
        if not config:
            # English fallback
            if level == "EMERGENCY":
                return f"EMERGENCY: Evacuate {village} immediately. Move to high ground."
            return f"Flood warning: {village} at risk in {hours} hours. Prepare to evacuate."

        templates = config.get("alert_templates", {})
        template = templates.get(level, templates.get("WARNING", ""))

        if not template:
            return f"Flood alert for {village}"

        return template.format(village=village, hours=hours)

    def get_supported_languages(self) -> list[dict]:
        """Return list of all supported languages with status."""
        return [
            {
                "code": code,
                "name": config["name"],
                "active": config["active"],
                "asr": config["asr"],
                "tts": config["tts"],
                "classifier": config.get("classifier_model", "keyword_only"),
                "n_keywords": len(config.get("flood_keywords", [])),
            }
            for code, config in GLOBAL_LANGUAGE_CONFIG.items()
        ]
